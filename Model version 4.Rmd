---
title: "Kaggle: Model version 4"
always_allow_html: true
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,tidy.opts=list(width.cutoff=80), tidy=FALSE) 
```

```{r package, message=FALSE, warning=FALSE}
library(lubridate)
library(ggplot2)
library(forecast)  
library(Kendall)
library(tseries)
library(outliers)
library(tidyverse)
library(smooth)
library(zoo)
library(kableExtra)
library(readxl)
library(xts)
```
##Data Import and Primary Cleaning
```{r}
#Importing time series data (relative humidity and temperature optional but importing)

#load data: this is daily data, with 24 different sensors
load_data <- read_excel(
  path = "./Data/load.xlsx",
  sheet = 1
)

#There are 6 NA  andd 17 zeros in data. They would have low impact in the overall
sum(is.na(load_data))
sum(load_data == 0, na.rm = TRUE)

#relative humidity: hourly data, with 28 different sensors
#I would estimate a mean 
relative_humidity_data <- read_excel(
  path = "./Data/relative_humidity.xlsx",
  sheet = 1
)

#There are 0 NA and 30 zeros. They would have low impact
sum(is.na(relative_humidity_data))
sum(relative_humidity_data == 0, na.rm = TRUE)

#temperature data: hourly data, with 28 different sensors
temperature_data <- read_excel(
  path = "./Data/temperature.xlsx",
  sheet = 1
)

#There are 0 NA and one zero. They would have low impact
sum(is.na(temperature_data))
sum(temperature_data == 0, na.rm = TRUE)

```

```{r}
#Processing load data - wrangling to allow the estimation per year, month, day, hour
load_processed <- load_data %>%
  pivot_longer(
    cols = starts_with("h"), 
    names_to = "hour", 
    values_to = "electricity_demand"
  ) %>%
  mutate(
    hour = as.integer(sub("h", "", hour)),  # Extract numeric part from "h1", "h2", etc.
    date = ymd(date),  
    year = year(date), 
    month = month(date), 
    day = day(date)
  ) %>% 
  select(date, year, month, day, hour, electricity_demand)

# Processing Humidity Data: wrangling to allow the estimation per year, month, day, hour
humidity_processed <- relative_humidity_data %>%
  pivot_longer(
    cols = starts_with("rh"), 
    names_to = "hour", 
    values_to = "relative_humidity"
  ) %>%
  mutate(
    hour = as.integer(gsub("[^0-9]", "", hour)),  # Extract only numeric characters (e.g., "rh_ws15" becomes 15)
    date = ymd(date),  
    year = year(date), 
    month = month(date), 
    day = day(date)
  ) %>% 
  select(date, year, month, day, hour, relative_humidity)

# Processing Temperature Data: wrangling to allow the estimation per year, month, day, hour
temp_processed <- temperature_data %>%
  pivot_longer(
    cols = starts_with("t"), 
    names_to = "hour", 
    values_to = "temperature"  # Corrected: use "temperature" instead of "relative_humidity"
  ) %>%
  mutate(
    hour = as.integer(gsub("[^0-9]", "", hour)),  # Extract numeric part
    date = ymd(date),  
    year = year(date), 
    month = month(date), 
    day = day(date)
  ) %>% 
  select(date, year, month, day, hour, temperature)



```
## Converting to daily by taking averages

```{r}
# Converting each processed dataset to daily values
daily_load <- load_processed %>%
  group_by(date) %>%
  summarise(daily_avg_load = mean(electricity_demand, na.rm = TRUE)) %>%
  ungroup()

daily_humidity <- humidity_processed %>%
  group_by(date) %>%
  summarise(daily_avg_humidity = mean(relative_humidity, na.rm = TRUE)) %>%
  ungroup()

daily_temp <- temp_processed %>%
  group_by(date) %>%
  summarise(daily_avg_temp = mean(temperature, na.rm = TRUE)) %>%
  ungroup()

```
## Merging the daily datasets to a full daily dataset 

```{r}
# Merging the daily datasets into one full dataset by date
full_daily <- daily_load %>%
  inner_join(daily_temp, by = "date") %>%
  inner_join(daily_humidity, by = "date") %>%
  arrange(date)

# Preview the merged full dataset
head(full_daily)
```
##Converting to time series object

```{r message=FALSE, warning=FALSE}
# Create the daily time series object from the merged full_daily dataset
# I use msts() to capture both weekly (7-day) and annual (365.25-day) seasonal patterns.
ts_electricity_daily <- msts(full_daily$daily_avg_load, 
                              seasonal.periods = c(7, 365.25), 
                              start = decimal_date(as.Date("2005-01-01")))

# I plot the full daily series to verify it looks as expected.
autoplot(ts_electricity_daily) + ggtitle("Electricity Demand: Daily")

# Now, I split the time series into training and test sets.
# The training set is from January 1, 2005, to December 31, 2009.
# The test set (for validation) covers January 1 to February 28, 2010.
# I use the window() function to create these subsets.

ts_daily_train <- window(ts_electricity_daily, end = c(2009, 365))
ts_daily_test  <- window(ts_electricity_daily, start = c(2010, 1), end = c(2010, 59))

# I visualize the training and test sets to confirm the split.
autoplot(ts_daily_train) + ggtitle("Training Set: Daily Demand (2005-2009)")
autoplot(ts_daily_test) + ggtitle("Test Set: Daily Demand (Jan-Feb 2010)")
```

### Testing Model 1: STL + ETS
```{r ETS, echo=TRUE, message=FALSE, warning=FALSE}

# Setting Forecasting horizon: number of days in the test set
horizon <- length(ts_daily_test)

# Fit and forecast using STL decomposition combined with ETS on the training data
electricity_fit <- stlf(ts_daily_train, 
                         h = horizon, 
                         method = "ets", 
                         s.window = "periodic", 
                         robust = TRUE)

# Plot the forecast for the test period
autoplot(electricity_fit) + 
  ggtitle("Model 1: STL + ETS Forecast (Test Set)") +
  ylab("Electricity Demand January-February 2010")

# Overlay the forecast on the full series (optional)
autoplot(ts_electricity_daily) +
  autolayer(electricity_fit, series = "STL + ETS", PI = FALSE) +
  ggtitle("Model 1: STL + ETS Forecast vs. Observed") +
  ylab("Electricity Demand January-February 2010")

accuracy_stl_ets <- accuracy(electricity_fit, ts_daily_test)
accuracy_stl_ets

```
### Testing Model 2: ARIMA + Fourier
```{r ARIMA, echo=TRUE, message=FALSE, warning=FALSE}
#Fit arima model with fourier terms as exogenous regressors
# seasonal = FALSE is the same as P=D=Q=0
# play with K by changing it to K=c(2,2), K=c(2,4), K=c(2,6), etc. The higher teh K the longer it will take to converge, because R will try more models.

# Generating Fourier terms for the training set
fourier_terms_train <- fourier(ts_daily_train, K = c(2, 6))

# Fitting an ARIMA model with these Fourier terms as exogenous regressors
ARIMA_Four_fit <- auto.arima(ts_daily_train, 
                             xreg = fourier_terms_train, 
                             seasonal = FALSE, 
                             lambda = 0)

# Generating Fourier terms for the forecasting period
fourier_terms_test <- fourier(ts_daily_train, K = c(2, 6), h = horizon)

# Forecasting using the fitted ARIMA model
ARIMA_Four_for <- forecast(ARIMA_Four_fit, 
                           xreg = fourier_terms_test, 
                           h = horizon)

# Plotting the forecast for the test period
autoplot(ARIMA_Four_for) + 
  ggtitle("Model 2: ARIMA + Fourier Forecast (Test Set)") +
  ylab("Electricity Demand January-February 2010")

# Overlaying on the full series
autoplot(ts_electricity_daily) +
  autolayer(ARIMA_Four_for, series = "ARIMA + Fourier", PI = FALSE) +
  ggtitle("Model 2: ARIMA + Fourier Forecast vs. Observed") +
  ylab("Electricity Demand January-February 2010")

# Accuracy Test
accuracy_arima_four <- accuracy(ARIMA_Four_for, ts_daily_test)
accuracy_arima_four

```
### Testing Model 3:  TBATS
```{r TBATS, echo=TRUE, message=FALSE, warning=FALSE}
# Fitting a TBATS model on the training data
fit_tbats <- tbats(ts_daily_train)

# Forecasting for the test period using the TBATS model
forecast_tbats <- forecast(fit_tbats, h = horizon)

# Plotting the TBATS forecast for the test period
autoplot(forecast_tbats) + 
  ggtitle("Model 3: TBATS Forecast (Test Set)") +
  ylab("Electricity Demand January-February 2010")

# Creating the data frame combining the dates and the forecasted values
forecast_dates <- seq(from = as.Date("2010-01-01"), by = "day", length.out = horizon)
forecast_TBATS_train <- data.frame(
  date = forecast_dates,
  forecast_demand_train = forecast_tbats$mean
)

# Accuracy Test
accuracy_tbats <- accuracy(forecast_tbats, ts_daily_test)
accuracy_tbats
```

## Model Comparison:
```{r}
## Model Comparison for 3 Models

# I used the accuracy metrics from my validation (test) set forecasts
comparison <- data.frame(
  Model = c("STL+ETS", "ARIMA+Fourier", "TBATS"),
  MSE = c(accuracy_stl_ets[1, "RMSE"]^2,
          accuracy_arima_four[1, "RMSE"]^2,
          accuracy_tbats[1, "RMSE"]^2),
  MAE = c(accuracy_stl_ets[1, "MAE"],
          accuracy_arima_four[1, "MAE"],
          accuracy_tbats[1, "MAE"]),
  MAPE = c(accuracy_stl_ets[1, "MAPE"],
           accuracy_arima_four[1, "MAPE"],
           accuracy_tbats[1, "MAPE"])
)
kable(comparison, caption = "Model Comparison on Validation Data")

```

## Final forecast for all models
```{r}
# submission forecast horizon: 59 days (from Jan 1, 2011 to Feb 28, 2011)
horizon_final <- 59

# I create the full time series object from my merged daily dataset (full_daily).
# This msts object captures both weekly (7-day) and annual (365.25-day) seasonal patterns.
full_ts <- msts(full_daily$daily_avg_load, 
                seasonal.periods = c(7, 365.25), 
                start = decimal_date(as.Date("2005-01-01")))

### Final Forecast using STL + ETS
# I re-fit the STL + ETS model on the full time series and forecast for the submission period.
final_forecast_stl <- stlf(full_ts, 
                           h = horizon_final, 
                           method = "ets", 
                           s.window = "periodic", 
                           robust = TRUE)

# Plot
autoplot(final_forecast_stl) + 
  ggtitle("Model 1: STL_ETS (Full Set)") +
  ylab("Electricity Demand")

# I create a data frame for the STL+ETS forecast using the provided template.
final_forecast_stl_df <- data.frame(
  date = seq(as.Date("2011-01-01"), by = "day", length.out = horizon_final),
  Model = "STL+ETS",
  forecast = as.numeric(final_forecast_stl$mean)
)

### Final Forecast using ARIMA + Fourier Terms
# I generate Fourier terms on the full time series

fourier_terms_full <- fourier(full_ts, K = c(2, 6))
# ARIMA model on the full time series using these Fourier terms as exogenous regressors.
fit_arima_four_full <- auto.arima(full_ts, xreg = fourier_terms_full, seasonal = FALSE, lambda = 0)
# Fourier terms for the submission period forecast.
fourier_terms_sub <- fourier(full_ts, K = c(2, 6), h = horizon_final)
# Forecasting using the fitted ARIMA model.
final_forecast_arima <- forecast(fit_arima_four_full, xreg = fourier_terms_sub, h = horizon_final)
# creating a data frame for the ARIMA+Fourier forecast.
final_forecast_arima_df <- data.frame(
  date = seq(as.Date("2011-01-01"), by = "day", length.out = horizon_final),
  Model = "ARIMA+Fourier",
  forecast = as.numeric(final_forecast_arima$mean)
)

### Final Forecast using TBATS
# TBATS model on the full time series.
fit_tbats_full <- tbats(full_ts)
# forecast for the submission period using the TBATS model.
final_forecast_tbats <- forecast(fit_tbats_full, h = horizon_final)
# data frame for the TBATS forecast.
final_forecast_tbats_df <- data.frame(
  date = seq(as.Date("2011-01-01"), by = "day", length.out = horizon_final),
  Model = "TBATS",
  forecast = as.numeric(final_forecast_tbats$mean)
)
```
### Saving the forecast
```{r}
# STL forecast
write.csv(final_forecast_stl_df, file = "submission_forecast_stl.csv", row.names = FALSE)

# ARIMA forecast
write.csv(final_forecast_arima_df, file = "submission_forecast_arima.csv", row.names = FALSE)

# TBATS forecast
write.csv(final_forecast_tbats_df, file = "submission_forecast_tbats.csv", row.names = FALSE)
```


